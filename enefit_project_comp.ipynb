{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 57236,
          "databundleVersionId": 7230081,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30587,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-Energy-Comp/blob/main/enefit_project_comp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "import lightgbm as lgb\n",
        "import optuna"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "PEWOCiWD9F6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MonthlyKFold:\n",
        "    def __init__(self, n_splits=3):\n",
        "        self.n_splits = n_splits\n",
        "    def split(self, X, y, groups=None):\n",
        "        dates = 12 * X[\"year\"] + X[\"month\"]\n",
        "        timesteps = sorted(dates.unique().tolist())\n",
        "        X = X.reset_index()\n",
        "        for t in timesteps[-self.n_splits:]:\n",
        "            idx_train = X[dates.values < t].index\n",
        "            idx_test = X[dates.values == t].index\n",
        "            yield idx_train, idx_test\n",
        "    def get_n_splits(self, X, y, groups=None):\n",
        "        return self.n_splits"
      ],
      "metadata": {
        "trusted": true,
        "id": "iK0lfj249F6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_pandas(X, y=None):\n",
        "    cat_cols = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"category_1\"]\n",
        "    if y is not None:\n",
        "        df = pd.concat([X.to_pandas(), y.to_pandas()], axis=1)\n",
        "    else:\n",
        "        df = X.to_pandas()\n",
        "    df = df.set_index(\"row_id\")\n",
        "    df[cat_cols] = df[cat_cols].astype(\"category\")\n",
        "    df[\"target_mean\"] = df[[f\"target_{i}\" for i in range(1, 7)]].mean(1)\n",
        "    df[\"target_std\"] = df[[f\"target_{i}\" for i in range(1, 7)]].std(1)\n",
        "    df[\"target_ratio\"] = df[\"target_6\"] / (df[\"target_7\"] + 1e-3)\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "id": "pkec2e4y9F6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter"
      ],
      "metadata": {
        "id": "wvmCA5FHvf2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lgb_objective(trial):\n",
        "    params = {\n",
        "        'n_iter'           : 1000,\n",
        "        'verbose'          : -1,\n",
        "        'random_state'     : 42,\n",
        "        'objective'        : 'l2',\n",
        "        'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'colsample_bynode' : trial.suggest_float('colsample_bynode', 0.5, 1.0),\n",
        "        'lambda_l1'        : trial.suggest_float('lambda_l1', 1e-2, 10.0),\n",
        "        'lambda_l2'        : trial.suggest_float('lambda_l2', 1e-2, 10.0),\n",
        "        'min_data_in_leaf' : trial.suggest_int('min_data_in_leaf', 4, 256),\n",
        "        'max_depth'        : trial.suggest_int('max_depth', 5, 10),\n",
        "        'max_bin'          : trial.suggest_int('max_bin', 32, 1024),\n",
        "    }\n",
        "    model  = lgb.LGBMRegressor(**params)\n",
        "    X, y   = df_train.drop(columns=[\"target\"]), df_train[\"target\"]\n",
        "    cv     = MonthlyKFold(1)\n",
        "    scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error')\n",
        "    return -1 * np.mean(scores)"
      ],
      "metadata": {
        "trusted": true,
        "id": "UpjmRMGP9F6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering\n"
      ],
      "metadata": {
        "id": "7MAmk-OPxcWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "def convert_to_polars(*dfs):\n",
        "    \"\"\"Converts a list of dataframes to Polars DataFrames.\"\"\"\n",
        "    return [pl.DataFrame(df) if not isinstance(df, pl.DataFrame) else df for df in dfs]\n",
        "def process_datetime(df, column_name, is_date=False):\n",
        "    \"\"\"Processes datetime columns to ensure correct format.\"\"\"\n",
        "    if column_name in df.columns:\n",
        "        if is_date and df.dtypes[df.columns.index(column_name)] == pl.Date:\n",
        "            df = df.with_columns(pl.col(column_name).cast(pl.Date))\n",
        "        elif not is_date and df.dtypes[df.columns.index(column_name)] == pl.Datetime:\n",
        "            df = df.with_columns(pl.col(column_name).cast(pl.Datetime))\n",
        "    return df\n",
        "def process_location(df):\n",
        "    \"\"\"Converts latitude and longitude to float.\"\"\"\n",
        "    return df.with_columns(\n",
        "        pl.col(\"latitude\").cast(pl.Float32),\n",
        "        pl.col(\"longitude\").cast(pl.Float32)\n",
        "    )\n",
        "def join_dataframes(df_main, dfs, join_conditions, suffixes):\n",
        "    \"\"\"Joins multiple dataframes with specified conditions and suffixes.\"\"\"\n",
        "    for df, condition, suffix in zip(dfs, join_conditions, suffixes):\n",
        "        if isinstance(condition, list):\n",
        "            condition_check = all(col in df_main.columns and col in df.columns for col in condition)\n",
        "        else:\n",
        "            condition_check = condition in df_main.columns and condition in df.columns\n",
        "        if condition_check:\n",
        "            df_main = df_main.join(df, on=condition, how=\"left\", suffix=suffix)\n",
        "        else:\n",
        "            print(f\"Skipping join for {suffix} due to missing column in condition: {condition}\")\n",
        "    return df_main\n",
        "def add_time_features(df):\n",
        "    \"\"\"Adds time-related features to the dataframe.\"\"\"\n",
        "    if \"datetime\" in df.columns and df.dtypes[df.columns.index(\"datetime\")] in [pl.Datetime, pl.Date]:\n",
        "        df = df.with_columns(\n",
        "            pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n",
        "            pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
        "            pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
        "            pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
        "            pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
        "            pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
        "            (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n",
        "            (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n",
        "            (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n",
        "            (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\")\n",
        "        )\n",
        "    else:\n",
        "        print(\"Warning: 'datetime' column not found. Time features cannot be added.\")\n",
        "    return df\n",
        "def feature_eng(df_data, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target):\n",
        "    df_data, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target = convert_to_polars(df_data, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target)\n",
        "    df_data = process_datetime(df_data, \"datetime\")\n",
        "    df_client = process_datetime(df_client, \"date\", is_date=True)\n",
        "    df_gas = process_datetime(df_gas, \"forecast_date\", is_date=True)\n",
        "    df_electricity = process_datetime(df_electricity, \"forecast_date\")\n",
        "    df_location = process_location(df_location)\n",
        "    df_forecast = process_datetime(df_forecast, \"forecast_datetime\")\n",
        "    df_historical = process_datetime(df_historical, \"datetime\")\n",
        "    join_conditions = [\n",
        "        \"date\",\n",
        "        [\"county\", \"is_business\", \"product_type\", \"date\"],\n",
        "        \"datetime\",\n",
        "        \"datetime\",\n",
        "        \"datetime\",\n",
        "        \"datetime\",\n",
        "        [\"county\", \"datetime\"],\n",
        "        \"datetime\"\n",
        "    ]\n",
        "    suffixes = [\"_gas\", \"_client\", \"_elec\", \"_fcast\", \"_hist\", \"_loc\", \"_target\"]\n",
        "    df_data = join_dataframes(df_data, [df_gas, df_client, df_electricity, df_forecast, df_historical, df_location, df_target], join_conditions, suffixes)\n",
        "    df_data = add_time_features(df_data)\n",
        "    df_data = df_data.drop([\"date\", \"datetime\", \"hour\", \"dayofyear\"])\n",
        "    return df_data\n"
      ],
      "metadata": {
        "id": "UYofNURu_2qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Variables"
      ],
      "metadata": {
        "id": "Gn9cdSMD9F6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n",
        "data_cols        = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime', 'row_id']\n",
        "client_cols      = ['product_type', 'county', 'eic_count', 'installed_capacity', 'is_business', 'date']\n",
        "gas_cols         = ['forecast_date', 'lowest_price_per_mwh', 'highest_price_per_mwh']\n",
        "electricity_cols = ['forecast_date', 'euros_per_mwh']\n",
        "forecast_cols    = ['latitude', 'longitude', 'hours_ahead', 'temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid', 'cloudcover_total', '10_metre_u_wind_component', '10_metre_v_wind_component', 'forecast_datetime', 'direct_solar_radiation', 'surface_solar_radiation_downwards', 'snowfall', 'total_precipitation']\n",
        "historical_cols  = ['datetime', 'temperature', 'dewpoint', 'rain', 'snowfall', 'surface_pressure','cloudcover_total','cloudcover_low','cloudcover_mid','cloudcover_high','windspeed_10m','winddirection_10m','shortwave_radiation','direct_solar_radiation','diffuse_radiation','latitude','longitude']\n",
        "location_cols    = ['longitude', 'latitude', 'county']\n",
        "target_cols      = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']\n",
        "save_path = None\n",
        "load_path = None"
      ],
      "metadata": {
        "trusted": true,
        "id": "zx4JfvPl9F6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data        = pl.read_csv(os.path.join(root, \"train.csv\"), columns=data_cols, try_parse_dates=True)\n",
        "df_client      = pl.read_csv(os.path.join(root, \"client.csv\"), columns=client_cols, try_parse_dates=True)\n",
        "df_gas         = pl.read_csv(os.path.join(root, \"gas_prices.csv\"), columns=gas_cols, try_parse_dates=True)\n",
        "df_electricity = pl.read_csv(os.path.join(root, \"electricity_prices.csv\"), columns=electricity_cols, try_parse_dates=True)\n",
        "df_forecast    = pl.read_csv(os.path.join(root, \"forecast_weather.csv\"), columns=forecast_cols, try_parse_dates=True)\n",
        "df_historical  = pl.read_csv(os.path.join(root, \"historical_weather.csv\"), columns=historical_cols, try_parse_dates=True)\n",
        "df_location    = pl.read_csv(os.path.join(root, \"weather_station_to_county_mapping.csv\"), columns=location_cols, try_parse_dates=True)\n",
        "df_target      = df_data.select(target_cols)\n",
        "schema_data        = df_data.schema\n",
        "schema_client      = df_client.schema\n",
        "schema_gas         = df_gas.schema\n",
        "schema_electricity = df_electricity.schema\n",
        "schema_forecast    = df_forecast.schema\n",
        "schema_historical  = df_historical.schema\n",
        "schema_target      = df_target.schema"
      ],
      "metadata": {
        "trusted": true,
        "id": "ntnXGXI39F6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df_data.drop(\"target\"), df_data.select(\"target\")\n",
        "X = feature_eng(X, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target)\n",
        "df_train = to_pandas(X, y)\n",
        "df_train = df_train[df_train[\"target\"].notnull() & df_train[\"year\"].gt(2021)]\n",
        "df_train.info(verbose=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mk3CrqpS9F6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning"
      ],
      "metadata": {
        "id": "pgM4VhGW9F6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {\n",
        "    'n_iter'           : 900,\n",
        "    'verbose'          : -1,\n",
        "    'objective'        : 'l2',\n",
        "    'learning_rate'    : 0.05689066836106983,\n",
        "    'colsample_bytree' : 0.8915976762048253,\n",
        "    'colsample_bynode' : 0.5942203285139224,\n",
        "    'lambda_l1'        : 3.6277555139102864,\n",
        "    'lambda_l2'        : 1.6591278779517808,\n",
        "    'min_data_in_leaf' : 186,\n",
        "    'max_depth'        : 9,\n",
        "    'max_bin'          : 813,\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "id": "UzMaXRoU9F6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "BMRSXOv39F6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if load_path is not None:\n",
        "    model = pickle.load(open(load_path, \"rb\"))\n",
        "else:\n",
        "    model = VotingRegressor([\n",
        "        ('lgb_1', lgb.LGBMRegressor(**best_params, random_state=100)),\n",
        "        ('lgb_2', lgb.LGBMRegressor(**best_params, random_state=101)),\n",
        "        ('lgb_3', lgb.LGBMRegressor(**best_params, random_state=102)),\n",
        "        ('lgb_4', lgb.LGBMRegressor(**best_params, random_state=103)),\n",
        "        ('lgb_5', lgb.LGBMRegressor(**best_params, random_state=104)),\n",
        "    ])\n",
        "    model.fit(\n",
        "        X=df_train.drop(columns=[\"target\"]),\n",
        "        y=df_train[\"target\"]\n",
        "    )\n",
        "if save_path is not None:\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        pickle.dump(model, f)"
      ],
      "metadata": {
        "trusted": true,
        "id": "iKaH3Phl9F6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction\n"
      ],
      "metadata": {
        "id": "Xx7nIZyR9F6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import enefit\n",
        "env = enefit.make_env()\n",
        "iter_test = env.iter_test()\n",
        "for (test, revealed_targets, client, historical_weather,\n",
        "        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n",
        "    test = test.rename(columns={\"prediction_datetime\": \"datetime\"})\n",
        "    df_test           = pl.from_pandas(test[data_cols[1:]], schema_overrides=schema_data)\n",
        "    df_client         = pl.from_pandas(client[client_cols], schema_overrides=schema_client)\n",
        "    df_gas            = pl.from_pandas(gas_prices[gas_cols], schema_overrides=schema_gas)\n",
        "    df_electricity    = pl.from_pandas(electricity_prices[electricity_cols], schema_overrides=schema_electricity)\n",
        "    df_new_forecast   = pl.from_pandas(forecast_weather[forecast_cols], schema_overrides=schema_forecast)\n",
        "    df_new_historical = pl.from_pandas(historical_weather[historical_cols], schema_overrides=schema_historical)\n",
        "    df_new_target     = pl.from_pandas(revealed_targets[target_cols], schema_overrides=schema_target)\n",
        "    df_forecast       = pl.concat([df_forecast, df_new_forecast]).unique()\n",
        "    df_historical     = pl.concat([df_historical, df_new_historical]).unique()\n",
        "    df_target         = pl.concat([df_target, df_new_target]).unique()\n",
        "    X_test = feature_eng(df_test, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target)\n",
        "    X_test = to_pandas(X_test)\n",
        "    sample_prediction[\"target\"] = model.predict(X_test).clip(0)\n",
        "    env.predict(sample_prediction)"
      ],
      "metadata": {
        "trusted": true,
        "id": "bWbKTrs79F6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}