{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOsmNfvp8kcVE1uqPzLfnFL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-Energy-Comp/blob/main/enefit_lgbm_baseline_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries and Packages"
      ],
      "metadata": {
        "id": "7FXkM_mYjAHG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOov_425imOY"
      },
      "outputs": [],
      "source": [
        "import os  # Import the os module for interacting with the operating system\n",
        "import gc  # Import the garbage collector module for memory management\n",
        "\n",
        "import numpy as np               # Import numpy for numerical operations and array handling\n",
        "import pandas as pd              # Import pandas for data manipulation and analysis\n",
        "import matplotlib.pyplot as plt  # Import matplotlib for creating static, animated, and interactive visualizations\n",
        "\n",
        "import seaborn as sns  # Import seaborn for statistical data visualization\n",
        "\n",
        "from sklearn.model_selection import cross_val_score  # Import cross_val_score for cross-validation of models\n",
        "\n",
        "import xgboost as xgb   # Import XGBoost for gradient boosting framework\n",
        "import lightgbm as lgb  # Import LightGBM for gradient boosting framework\n",
        "import catboost as cb   # Import CatBoost for gradient boosting on decision trees\n",
        "\n",
        "import optuna  # Import Optuna for hyperparameter optimization\n",
        "import shap    # Import SHAP for explaining the output of machine learning models\n",
        "\n",
        "from datetime import datetime  # Import datetime for handling date and time\n",
        "import pytz                    # Import pytz for handling timezone information\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input Data Files"
      ],
      "metadata": {
        "id": "eRB1xUn9lJyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating through all files in the '/kaggle/input' directory and printing their full paths\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        ""
      ],
      "metadata": {
        "id": "z21nB-SqlKWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data"
      ],
      "metadata": {
        "id": "L2Hu5VxGlUr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
        "# df_gprice = pd.read_csv(os.path.join(data_dir, \"gas_prices.csv\"))\n",
        "# df_eprice = pd.read_csv(os.path.join(data_dir, \"electricity_prices.csv\"))\n",
        "# df_client = pd.read_csv(os.path.join(data_dir, \"client.csv\"))\n",
        "# df_weather = pd.read_csv(os.path.join(data_dir, \"forecast_weather.csv\"))\n",
        "# df_hweather = pd.read_csv(os.path.join(data_dir, \"historical_weather.csv\"))\n",
        "\n",
        "df_train[\"datetime\"] = pd.to_datetime(df_train[\"datetime\"])\n",
        "\n",
        "df_train[\"month\"]   = df_train[\"datetime\"].dt.month\n",
        "df_train[\"day\"]     = df_train[\"datetime\"].dt.day\n",
        "df_train[\"weekday\"] = df_train[\"datetime\"].dt.weekday\n",
        "df_train[\"hour\"]    = df_train[\"datetime\"].dt.hour\n",
        "\n",
        "df_train[\"county\"]         = df_train[\"county\"].astype(\"category\")\n",
        "df_train[\"is_business\"]    = df_train[\"is_business\"].astype(\"category\")\n",
        "df_train[\"product_type\"]   = df_train[\"product_type\"].astype(\"category\")\n",
        "df_train[\"is_consumption\"] = df_train[\"is_consumption\"].astype(\"category\")\n",
        "\n",
        "df_train = df_train.set_index([\"row_id\", \"datetime\"])\n",
        "df_train = df_train.drop(columns=[\"prediction_unit_id\", \"data_block_id\"])\n",
        "\n",
        "df_train = df_train.dropna(subset=[\"target\"])\n"
      ],
      "metadata": {
        "id": "sSHFDofglbCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}